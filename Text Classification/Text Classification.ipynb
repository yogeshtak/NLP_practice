{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT CLASSIFICATION\n",
    "\n",
    "#### Model Evaluation: \n",
    "\n",
    "**Accuracy** - Accuracy in classification problem is the number of correct predictions made by the model divided by the total number of predictions. **Accuracy is useful when target classes are well balanced.** For example, If we are predicting SPAM messages, we would have roughly the same amount of spam messages as we have legit messages. **Accuracy is not good choice with unbalanced classes.** Imagine we have 99 legit messgaes and 1 spam message. Our model will have 99% accuracy bit that's not correct.\n",
    "\n",
    "In this situation we'll understand Recall, Precision and f1 score.\n",
    "\n",
    "**Recall** - Ability to find **all** the relevant cases within a dataset. **Number of true positive divided by the number of true positives plus the number of false negatives.**\n",
    "\n",
    "**Precision** - Ability of a classification model to identify **only** the relevant data points. **True positives divided by the number of true positives plus the number of false positives**\n",
    "\n",
    "Recall expresses the ability to find all relevant instances in a dataset, precision expresses the proportion of the data points our model says was relevant actually were relevant.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/888/1*7J08ekAwupLBegeUI8muHA.png\" />\n",
    "\n",
    "**F1-Score** - Combination of Recall and Precision (Optimal blend of precision and Recall). F1 score is **the harmonic mean of precision and recall taking both metrics into account in the following equation:**\n",
    "\n",
    "<img src=\"https://www.mikulskibartosz.name/assets/images/2019-02-04-f1-score-explained/formula.png\" width=\"500\" />\n",
    "\n",
    "We use the harmonic mean instead of a simple avergae because it punishes extreme values. Example- A classiferwith a precision of 1.0 and a recall of 0.0 has a simple average of 0.5 but and F1 score of 0.\n",
    "\n",
    "Precision and Recall typically make more sense in the context of a confusion matrix.\n",
    "\n",
    "So, You sould have 4 separate groups at the end of testing:\n",
    "\n",
    "1. Correctly classified as True Legit Message\n",
    "2. Correctly classified as True Spam Message\n",
    "3. Incorrectly classified False Legit Message\n",
    "4. Incorrectly classifed Flase Spam Message\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/712/1*Z54JgbS4DUwWSknhDCvNTQ.png\" />\n",
    "<img src=\"1.PNG\" width =\"600\" />\n",
    "\n",
    "Flase Negative(FN) - Type II error\n",
    "False Positives (FP) - Type I error\n",
    "\n",
    "<img src=\"2.PNG\" width=\"600\" />\n",
    "<img src=\"3.PNG\" />\n",
    "\n",
    "**Which matrix is good to calculate in classification?** It all rally depends on the specific situation.\n",
    "\n",
    "#### Example: Imagine testing for disease.\n",
    "\n",
    "| n=165         | Predicted NO  | Predicted YES  |\n",
    "| ------------- |:-------------:|          -----:|\n",
    "| ACTUAL NO     | 50            |             10 |\n",
    "| ACTUAL YES    | 5             |            100 |\n",
    "\n",
    "*Example: Test for presence of disease*\n",
    "*NO = negative test = False = 0*\n",
    "*Yes = positive test = True = 1*\n",
    "\n",
    "| n=165          | **Predicted NO**| **Predicted YES**  | **Total** |\n",
    "| -------------  |:---------------:|              -----:|    -----: |\n",
    "| **ACTUAL NO**  | TN = 50         |            FP = 10 | **60**    |\n",
    "| **ACTUAL YES** | FN = 5          |           TP = 100 | **105**   |\n",
    "| **Total**      |           **55**|             **110**|\n",
    "\n",
    "**Basic Terminology**\n",
    "1. True Positives (TP)\n",
    "2. True Negatives (TN)\n",
    "3. False Positives (FP)\n",
    "4. False Negatives (FN)\n",
    "\n",
    "**Accuracy** - Overall, how often is it correct?\n",
    "(TP+TN)/Total = 150/165 = 0.91\n",
    "\n",
    "**Misclassification Rate(Error Rate)** Overall, how often is it wrong?\n",
    "(FP+FN)/Total = 15/165 = 0.09\n",
    "\n",
    "<img src=\"4.PNG\" width=\"400\" />\n",
    "\n",
    "[Checkout the wikipedia page - Very helpful](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "[Checkout GeeksforGeeks Page](https://www.geeksforgeeks.org/confusion-matrix-machine-learning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('smsspamcollection.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  message  length  punct\n",
       "0     False    False   False  False\n",
       "1     False    False   False  False\n",
       "2     False    False   False  False\n",
       "3     False    False   False  False\n",
       "4     False    False   False  False\n",
       "...     ...      ...     ...    ...\n",
       "5567  False    False   False  False\n",
       "5568  False    False   False  False\n",
       "5569  False    False   False  False\n",
       "5570  False    False   False  False\n",
       "5571  False    False   False  False\n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it will treat false as zero and true as one, so if there is any missing data, we'll be able to see\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Missing Data in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking te number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: label, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>We see that 4825 out of 5572 messages, or 86.6%, are ham.<br>This means that any machine learning model we create has to perform **better than 86.6%** to beat random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to build one simple machine learning model which will use length of message and Punctuation in message to predict Ham(legit) or spam messages. \n",
    "\n",
    "#### First we'll visualize this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green> It looks like there's a small range of values where a message is more likely to be a spam tham ham. So, Length of messgae is very important feature for machine learning model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "bins=1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label']=='ham']['punct'], bins=bins, alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['punct'], bins=bins, alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> This looks worse, there seem to be no values where one would pick spam over ham. We'll still try to build a machine learning classification model, but we should expect poor results. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X feature data\n",
    "#two [[]] because we're passing a list of columns\n",
    "X= df[['length','punct']]\n",
    "\n",
    "# y is our label\n",
    "y=df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (3900, 2)\n",
      "Shape of X_test: (1672, 2)\n",
      "Shape of y_train: (3900,)\n",
      "Shape of y_test: (1672,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue> **Our Model is now ready to predict** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#create a prediction \n",
    "predictions = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245     ham\n",
       "944      ham\n",
       "1044     ham\n",
       "2484     ham\n",
       "812      ham\n",
       "        ... \n",
       "2505     ham\n",
       "2525    spam\n",
       "4975     ham\n",
       "650     spam\n",
       "4463     ham\n",
       "Name: label, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1404   44]\n",
      " [ 219    5]]\n"
     ]
    }
   ],
   "source": [
    "#let's compare our results with y_test\n",
    "#one way of doing that is to create a confusion matrix\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the above outout see the below image\n",
    "<img src=\"2.PNG\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1404</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1404    44\n",
       "spam   219     5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can make confusion matrix less confusing by adding labels:\n",
    "df1 = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> These results are terrible! More spam messages were confused as ham (219) than correctly identified as spam(5), although a small number of ham messages (44) were confused as spam. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "    accuracy                           0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print a classififcation report\n",
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8427033492822966\n"
     ]
    }
   ],
   "source": [
    "#print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> This model performed *worse* than a classifier that assigned all messages as \"ham\" would have! </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a naive Bayes classifier:\n",
    "\n",
    "One of the most common and successful - classifer is naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1438   10]\n",
      " [ 224    0]]\n"
     ]
    }
   ],
   "source": [
    "predictions_NB = nb_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, predictions_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green> The total number of consusions dropped from 263(219+44) to 234(224+10) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92      1448\n",
      "        spam       0.00      0.00      0.00       224\n",
      "\n",
      "    accuracy                           0.86      1672\n",
      "   macro avg       0.43      0.50      0.46      1672\n",
      "weighted avg       0.75      0.86      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8600478468899522\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = Blue> Better, but still less accuarte than 86.6% </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a support vector machine (SVM) classifier\n",
    "\n",
    "Among the SVM options available, we'll use C-Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1373   75]\n",
      " [ 121  103]]\n"
     ]
    }
   ],
   "source": [
    "predictions_svc = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green> The total number of confusions dropped even further to 196(121+75). </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.93      1448\n",
      "        spam       0.58      0.46      0.51       224\n",
      "\n",
      "    accuracy                           0.88      1672\n",
      "   macro avg       0.75      0.70      0.72      1672\n",
      "weighted avg       0.87      0.88      0.88      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8827751196172249\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, predictions_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green> And finally we have a model which performs ***slightly*** better than a random chance. </font>\n",
    "\n",
    "Now, I am able to load a dataset, divide in into training and testing set, and perform simple analyses using scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
